# Chat - æœ€æ–°ç‰ˆãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆã¾ã¨ã‚æ©Ÿèƒ½ãƒ»è¤‡æ•°è¡Œç·¨é›†ãƒ»Rate Limitå¯¾å¿œï¼‰
# Version: 7.0.0
# Features: 
# - ã¾ã¨ã‚æ©Ÿèƒ½: AIã«ã‚ˆã‚‹ä¼šè©±å±¥æ­´ã®è¦ç´„ã¨ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
# - è¤‡æ•°è¡Œå…¥åŠ›: ç¶™ç¶šçš„ãªè¤‡æ•°è¡Œãƒ¢ãƒ¼ãƒ‰ã¨é«˜åº¦ãªç·¨é›†æ©Ÿèƒ½
# - é«˜é€Ÿãƒ¢ãƒ‡ãƒ«å¯¾å¿œ: --fastã‚¹ã‚¤ãƒƒãƒã§é«˜é€Ÿç‰ˆãƒ¢ãƒ‡ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆ
# - Rate Limitå¯¾å¿œ: æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã«ã‚ˆã‚‹è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤
# - æœ€æ–°AIãƒ¢ãƒ‡ãƒ«: å…¨ãƒ—ãƒ­ãƒã‚¤ãƒ€ãƒ¼ã®æœ€æ–°ãƒ¢ãƒ‡ãƒ«ã«å¯¾å¿œ

import sys
import os
import csv
import time
import importlib
from datetime import datetime
from langchain.prompts import (
    ChatPromptTemplate,
    SystemMessagePromptTemplate,
    HumanMessagePromptTemplate,
    MessagesPlaceholder
)
from langchain.schema.runnable import (
    RunnableLambda,
    RunnableSequence,
    RunnablePassthrough
)
from langchain.schema import AIMessage, HumanMessage
import argparse # argparseã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ

# Version information
VERSION = "7.0.0"
VERSION_DATE = "2025-07-26"

# AI Assistants configuration file
AI_ASSISTANTS_CONFIG_FILE = "ai_assistants_config.csv"

# Logs and summaries directories
LOGS_DIR = "logs"
SUMMARIES_DIR = "summaries"
SESSIONS_DIR = "sessions"  # çµ±åˆå‹ç”¨

# ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ãƒ¢ãƒ¼ãƒ‰è¨­å®š
FILE_ORGANIZATION_MODE = "separated"  # "separated" or "unified"

MAX_HISTORY_LENGTH = 10

def print_version_info():
    """ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º"""
    print(f"ğŸ¤– Chat - AI ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ v{VERSION} ({VERSION_DATE})")
    print("=" * 60)
    print("âœ¨ æ–°æ©Ÿèƒ½:")
    print("  ğŸ“‹ ã¾ã¨ã‚æ©Ÿèƒ½ - ä¼šè©±å±¥æ­´ã‚’AIãŒè¦ç´„ã—ã¦ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜")
    print("  ğŸ“ è¤‡æ•°è¡Œç·¨é›† - é«˜åº¦ãªè¡Œç·¨é›†æ©Ÿèƒ½ï¼ˆã‚‚ã¨ã„/ã¡ã‚ƒã„ã¡ã‚ƒã„ï¼‰")
    print("  âš¡ é«˜é€Ÿãƒ¢ãƒ‡ãƒ« - --fastã‚¹ã‚¤ãƒƒãƒã§é«˜é€Ÿç‰ˆã«åˆ‡ã‚Šæ›¿ãˆ")
    print("  ğŸ”„ Rate Limitå¯¾å¿œ - è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½")
    print("=" * 60)

class ConversationHistory:
    """ä¼šè©±å±¥æ­´ã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, max_length=10):
        self.max_length = max_length
        self.messages = []
    
    def add_message(self, message):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ """
        self.messages.append(message)
        # æœ€å¤§é•·ã‚’è¶…ãˆãŸå ´åˆã€å¤ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
        if len(self.messages) > self.max_length * 2:  # User/Assistant ãƒšã‚¢ã§ç®¡ç†
            self.messages = self.messages[-self.max_length * 2:]
    
    def get_messages(self):
        """ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒªã‚¹ãƒˆã‚’å–å¾—"""
        return self.messages
    
    def extend_messages(self, messages):
        """è¤‡æ•°ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’è¿½åŠ """
        self.messages.extend(messages)
        # æœ€å¤§é•·ã‚’è¶…ãˆãŸå ´åˆã€å¤ã„ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
        if len(self.messages) > self.max_length * 2:
            self.messages = self.messages[-self.max_length * 2:]

def load_ai_assistants_config():
    """CSVãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰AI Assistantsè¨­å®šã‚’èª­ã¿è¾¼ã‚€"""
    ai_assistants = {}
    
    if not os.path.exists(AI_ASSISTANTS_CONFIG_FILE):
        print(f"[ERROR] AI Assistantsè¨­å®šãƒ•ã‚¡ã‚¤ãƒ« '{AI_ASSISTANTS_CONFIG_FILE}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚")
        return ai_assistants
    
    try:
        with open(AI_ASSISTANTS_CONFIG_FILE, 'r', newline='', encoding='utf-8') as f:
            reader = csv.DictReader(f)
            for row in reader:
                assistant_name = row['assistant_name']
                ai_assistants[assistant_name] = {
                    'module': row['module'],
                    'class': row['class'],
                    'model': row['model'],
                    'fast_model': row.get('fast_model', '').strip()  # ç©ºæ–‡å­—åˆ—ã®å ´åˆã‚‚ã‚ã‚‹
                }
        print(f"[INFO] AI Assistantsè¨­å®šã‚’ {AI_ASSISTANTS_CONFIG_FILE} ã‹ã‚‰èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"[ERROR] AI Assistantsè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return {}
    
    return ai_assistants

def parse_arguments(ai_assistants):
    parser = argparse.ArgumentParser(
        description="Chat - AI ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆï¼ˆã¾ã¨ã‚æ©Ÿèƒ½ãƒ»è¤‡æ•°è¡Œç·¨é›†å¯¾å¿œï¼‰",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ä¾‹:
  python Chat.py                           # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã§é–‹å§‹
  python Chat.py -a ChatGPT --fast         # ChatGPTã®é«˜é€Ÿç‰ˆã‚’ä½¿ç”¨
  python Chat.py --latest                  # æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿
  python Chat.py -l 20250726_130500        # logs/ãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰ãƒ•ã‚¡ã‚¤ãƒ«åã§èª­ã¿è¾¼ã¿
  python Chat.py -l logs/conversation.csv  # ãƒ•ãƒ«ãƒ‘ã‚¹ã§èª­ã¿è¾¼ã¿
  python Chat.py -l log.csv -a Groq        # ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã‚€ãŒã€Groqã«åˆ‡ã‚Šæ›¿ãˆ

ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†:
  ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«: logs/ ãƒ•ã‚©ãƒ«ãƒ€ã«è‡ªå‹•ä¿å­˜
  ã¾ã¨ã‚ãƒ•ã‚¡ã‚¤ãƒ«: summaries/ ãƒ•ã‚©ãƒ«ãƒ€ã«è‡ªå‹•ä¿å­˜
  --latest: æœ€æ–°ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’è‡ªå‹•é¸æŠ

ãƒ¢ãƒ‡ãƒ«ç¶™ç¶šã‚ªãƒ—ã‚·ãƒ§ãƒ³:
  --confirm-model    : ãƒ­ã‚°èª­ã¿è¾¼ã¿æ™‚ã«æ¯å›ãƒ¢ãƒ‡ãƒ«é¸æŠã‚’ç¢ºèª
  --ignore-log-model : ãƒ­ã‚°ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ç„¡è¦–ã—ã¦æŒ‡å®šè¨­å®šã‚’å¼·åˆ¶ä½¿ç”¨

ç‰¹åˆ¥ã‚³ãƒãƒ³ãƒ‰:
  'multi' ã¾ãŸã¯ 'è¤‡æ•°è¡Œ'    : è¤‡æ•°è¡Œå…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã«åˆ‡ã‚Šæ›¿ãˆ
  'ã¾ã¨ã‚ã¦ãã ã•ã„'        : ä¼šè©±å±¥æ­´ã‚’AIãŒã¾ã¨ã‚ã¦ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜
  'ã‚‚ã¨ã„' / 'ã¡ã‚ƒã„ã¡ã‚ƒã„' : è¤‡æ•°è¡Œãƒ¢ãƒ¼ãƒ‰ã§ç›´å‰ã®è¡Œã‚’å‰Šé™¤
        """
    )
    # AIã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆåã®å¼•æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: Groq)
    parser.add_argument("-a", "--assistant", type=str, default="Groq", choices=ai_assistants.keys(),
                        help=f"Specify the AI assistant to use. Choices: {list(ai_assistants.keys())}")
    # ãƒ¢ãƒ‡ãƒ«åã®å¼•æ•° (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯é¸æŠã•ã‚ŒãŸã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã«ä¾å­˜)
    parser.add_argument("-m", "--model", type=str,
                        help="Specify the model name. If not provided, uses the default for the chosen assistant.")
    # èª­ã¿è¾¼ã‚€ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®å¼•æ•°
    parser.add_argument("-l", "--load-log", type=str, default=None,
                        help="Path to the CSV conversation log file to load and continue. Can specify just filename (searches in logs/ folder) or full path.")
    # æœ€æ–°ãƒ­ã‚°ã‚’è‡ªå‹•èª­ã¿è¾¼ã¿
    parser.add_argument("--latest", action="store_true",
                        help="Load the latest log file from logs folder automatically")
    # é«˜é€Ÿç‰ˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã™ã‚‹ã‚¹ã‚¤ãƒƒãƒ
    parser.add_argument("--fast", action="store_true",
                        help="Use fast version of the selected assistant (e.g., Groq -> GroqFast)")
    # ãƒ­ã‚°ç¶™ç¶šæ™‚ã®ãƒ¢ãƒ‡ãƒ«é¸æŠç¢ºèª
    parser.add_argument("--confirm-model", action="store_true",
                        help="Confirm model selection when loading from log file")
    # ãƒ•ã‚¡ã‚¤ãƒ«ç®¡ç†ãƒ¢ãƒ¼ãƒ‰
    parser.add_argument("--unified", action="store_true",
                        help="Use unified file organization (logs and summaries in same session folder)")
    # ãƒ­ã‚°ã®ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ç„¡è¦–ã—ã¦å¼·åˆ¶çš„ã«æŒ‡å®šè¨­å®šã‚’ä½¿ç”¨
    parser.add_argument("--ignore-log-model", action="store_true",
                        help="Ignore model settings from log file and use specified settings")
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³è¡¨ç¤º
    parser.add_argument("--version", action="version", version=f"Chat v{VERSION}")

    args = parser.parse_args()

    # --fast ã‚¹ã‚¤ãƒƒãƒãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€é«˜é€Ÿç‰ˆãƒ¢ãƒ‡ãƒ«ã«åˆ‡ã‚Šæ›¿ãˆ
    if args.fast:
        fast_model = ai_assistants[args.assistant].get('fast_model', '').strip()
        if fast_model:
            print(f"[INFO] --fast ã‚¹ã‚¤ãƒƒãƒã«ã‚ˆã‚Š {ai_assistants[args.assistant]['model']} ã‹ã‚‰ {fast_model} ã«åˆ‡ã‚Šæ›¿ãˆã¾ã™ã€‚")
            # ãƒ¢ãƒ‡ãƒ«åã‚’ç›´æ¥å¤‰æ›´ï¼ˆã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆåã¯å¤‰æ›´ã—ãªã„ï¼‰
            ai_assistants[args.assistant]['model'] = fast_model
        else:
            print(f"[WARNING] {args.assistant} ã«ã¯é«˜é€Ÿç‰ˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚é€šå¸¸ç‰ˆ {ai_assistants[args.assistant]['model']} ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")

    # ãƒ¢ãƒ‡ãƒ«åãŒæŒ‡å®šã•ã‚Œã¦ã„ãªã„å ´åˆã€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
    if args.model is None:
        args.model = ai_assistants[args.assistant]['model']

    return args

def find_latest_log():
    """logsãƒ•ã‚©ãƒ«ãƒ€ã‹ã‚‰æœ€æ–°ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    if not os.path.exists(LOGS_DIR):
        return None
    
    log_files = [f for f in os.listdir(LOGS_DIR) if f.endswith('.csv')]
    if not log_files:
        return None
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚½ãƒ¼ãƒˆï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—å½¢å¼ãªã®ã§æ–‡å­—åˆ—ã‚½ãƒ¼ãƒˆã§æ™‚ç³»åˆ—é †ã«ãªã‚‹ï¼‰
    log_files.sort(reverse=True)
    latest_log = os.path.join(LOGS_DIR, log_files[0])
    return latest_log

def resolve_log_path(log_path):
    """ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’è§£æ±ºï¼ˆãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã®å ´åˆã¯logsãƒ•ã‚©ãƒ«ãƒ€ã‚’æ¤œç´¢ï¼‰"""
    if log_path is None:
        return None
    
    # ãƒ•ãƒ«ãƒ‘ã‚¹ã¾ãŸã¯ç›¸å¯¾ãƒ‘ã‚¹ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆ
    if os.path.sep in log_path or log_path.endswith('.csv'):
        if os.path.exists(log_path):
            return log_path
        # logsãƒ•ã‚©ãƒ«ãƒ€å†…ã‚‚ç¢ºèª
        logs_path = os.path.join(LOGS_DIR, os.path.basename(log_path))
        if os.path.exists(logs_path):
            return logs_path
    
    # ãƒ•ã‚¡ã‚¤ãƒ«åã®ã¿ã®å ´åˆã€logsãƒ•ã‚©ãƒ«ãƒ€å†…ã‚’æ¤œç´¢
    if not log_path.endswith('.csv'):
        log_path += '.csv'
    
    logs_path = os.path.join(LOGS_DIR, log_path)
    if os.path.exists(logs_path):
        return logs_path
    
    return log_path  # å…ƒã®ãƒ‘ã‚¹ã‚’è¿”ã™ï¼ˆã‚¨ãƒ©ãƒ¼ã¯å‘¼ã³å‡ºã—å´ã§å‡¦ç†ï¼‰

# CSVã‹ã‚‰å±¥æ­´ã¨æœ€å¾Œã®è¨­å®šã‚’èª­ã¿è¾¼ã‚€é–¢æ•°
def load_history_from_csv(filepath):
    messages = []
    last_turn_id = 0
    last_ai_assistant = None
    last_model_name = None

    if not os.path.exists(filepath):
        print(f"[WARNING] æŒ‡å®šã•ã‚ŒãŸãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {filepath}")
        return messages, last_turn_id, last_ai_assistant, last_model_name

    try:
        with open(filepath, 'r', newline='', encoding='utf-8') as f:
            reader = csv.reader(f)
            header = next(reader)
            try:
                turn_id_index = header.index('TurnID')
                speaker_index = header.index('Speaker')
                content_index = header.index('Content')
                ai_assistant_index = header.index('AI_Assistant')
                model_name_index = header.index('ModelName')
            except ValueError as e:
                print(f"[ERROR] ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ãŒä¸æ­£ã§ã™: {e}. å¿…è¦ãªåˆ—: TurnID, Speaker, Content, AI_Assistant, ModelName")
                return [], 0, None, None

            current_last_assistant = None
            current_last_model = None
            current_last_id = 0

            for row in reader:
                try:
                    turn_id = int(row[turn_id_index])
                    speaker = row[speaker_index]
                    content = row[content_index]
                    if speaker == 'Assistant':
                        # ç©ºã§ãªã„å ´åˆã«æ›´æ–°ã™ã‚‹
                        assistant_in_row = row[ai_assistant_index]
                        model_in_row = row[model_name_index]
                        if assistant_in_row:
                             current_last_assistant = assistant_in_row
                        if model_in_row:
                             current_last_model = model_in_row

                    if speaker == 'User':
                        messages.append(HumanMessage(content=content))
                    elif speaker == 'Assistant':
                        messages.append(AIMessage(content=content))

                    current_last_id = max(current_last_id, turn_id)

                except IndexError:
                    print(f"[WARNING] ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¡Œã®å½¢å¼ãŒä¸æ­£ã§ã™: {row}")
                except ValueError:
                     print(f"[WARNING] TurnIDãŒæ•°å€¤ã§ã¯ã‚ã‚Šã¾ã›ã‚“: {row}")

            last_turn_id = current_last_id
            last_ai_assistant = current_last_assistant
            last_model_name = current_last_model

    except Exception as e:
        print(f"[ERROR] ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®èª­ã¿è¾¼ã¿ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return [], 0, None, None

    print(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« {filepath} ã‹ã‚‰ {len(messages)} ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚æœ€å¾Œã®ã‚¿ãƒ¼ãƒ³ID: {last_turn_id}")
    if last_ai_assistant and last_model_name:
         print(f"ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€å¾Œã®è¨­å®š: Assistant={last_ai_assistant}, Model={last_model_name}")
    return messages, last_turn_id, last_ai_assistant, last_model_name

def load_assistant(ai_assistants, ai_assistant, model_name):
    module_name = ai_assistants[ai_assistant]['module']
    class_name = ai_assistants[ai_assistant]['class']
    module = importlib.import_module(module_name)
    AssistantClass = getattr(module, class_name)
    
    # ChatTogetherã‚¯ãƒ©ã‚¹ã®å ´åˆã®ã¿ã€nãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã¨max_retriesã‚’è¿½åŠ 
    if class_name == 'ChatTogether':
        return AssistantClass(model=model_name, n=1, max_retries=3)
    else:
        return AssistantClass(model=model_name)

def create_prompt(ai_assistant):
    # system_message.txt ãŒå­˜åœ¨ã—ãªã„å ´åˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã‚’è¿½åŠ ï¼ˆä»»æ„ï¼‰
    prompt_messages = []
    # Anthropicã®Claudeãƒ¢ãƒ‡ãƒ«ã‚„xAIã®Grokãƒ¢ãƒ‡ãƒ«ã¯ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ã‚µãƒãƒ¼ãƒˆ
    if ai_assistant not in ['Gemini']:
        try:
            with open("system_message.txt", "r", encoding="utf-8") as file:
                system_content = file.read()
            prompt_messages.append(SystemMessagePromptTemplate.from_template(system_content))
        except FileNotFoundError:
             print("[WARNING] system_message.txt ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãªã—ã§ç¶šè¡Œã—ã¾ã™ã€‚")
        except Exception as e:
             print(f"[ERROR] system_message.txt ã®èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")

    prompt_messages.extend([
        MessagesPlaceholder(variable_name="history"),
        HumanMessagePromptTemplate.from_template("{input}")
    ])
    return ChatPromptTemplate.from_messages(prompt_messages)

def save_summary_to_file(summary_content, ai_assistant, model_name):
    """ã¾ã¨ã‚å†…å®¹ã‚’Foamå½¢å¼ã§ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜"""
    try:
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # summariesãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
        os.makedirs(SUMMARIES_DIR, exist_ok=True)
        
        summary_filename = os.path.join(SUMMARIES_DIR, f"{timestamp}.md")
        
        with open(summary_filename, 'w', encoding='utf-8') as f:
            # ã‚·ãƒ³ãƒ—ãƒ«ãªãƒ˜ãƒƒãƒ€ãƒ¼
            f.write(f"# Chat ä¼šè©±ã¾ã¨ã‚ {timestamp}\n\n")
            f.write(f"- **ä½œæˆæ—¥æ™‚**: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}\n")
            f.write(f"- **AI Assistant**: {ai_assistant}\n")
            f.write(f"- **Model**: {model_name}\n")
            f.write(f"- **ç”Ÿæˆè€…**: Chat v{VERSION}\n\n")
            f.write(f"---\n\n")
            
            # AIãŒç”Ÿæˆã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’ãã®ã¾ã¾æŒ¿å…¥
            f.write(summary_content)
            f.write(f"\n\n")
            
            f.write(f"---\n")
            f.write(f"*ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ Chat v{VERSION} ã«ã‚ˆã‚Šè‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸ*\n")
        
        print(f"\nğŸ“ ã¾ã¨ã‚ã‚’ {summary_filename} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
        return summary_filename
    except Exception as e:
        print(f"[ERROR] ã¾ã¨ã‚ãƒ•ã‚¡ã‚¤ãƒ«ã®ä¿å­˜ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        return None

def is_summary_request(user_input):
    """ã¾ã¨ã‚è¦æ±‚ã‹ã©ã†ã‹ã‚’åˆ¤å®š"""
    summary_keywords = [
        "ã¾ã¨ã‚ã¦ãã ã•ã„", "ã“ã“ã¾ã§ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„", "è¦ç´„ã—ã¦ãã ã•ã„",
        "ã¾ã¨ã‚ã¦", "è¦ç´„ã—ã¦", "æ•´ç†ã—ã¦ãã ã•ã„", "æ•´ç†ã—ã¦",
        "æŒ¯ã‚Šè¿”ã£ã¦ãã ã•ã„", "æŒ¯ã‚Šè¿”ã£ã¦", "ç·æ‹¬ã—ã¦ãã ã•ã„", "ç·æ‹¬ã—ã¦"
    ]
    user_lower = user_input.lower().strip()
    return any(keyword in user_lower for keyword in summary_keywords)

def create_conversation_summary(conversation_history):
    """ä¼šè©±å±¥æ­´ã‹ã‚‰ã¾ã¨ã‚ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ"""
    messages = conversation_history.get_messages()
    if not messages:
        return "ä¼šè©±å±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚"
    
    summary_text = "=== ä¼šè©±å±¥æ­´ ===\n\n"
    
    for i, message in enumerate(messages, 1):
        if hasattr(message, 'content'):
            if message.__class__.__name__ == 'HumanMessage':
                summary_text += f"ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ {i//2 + 1}ã€‘\n{message.content}\n\n"
            elif message.__class__.__name__ == 'AIMessage':
                summary_text += f"ã€ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆ {i//2 + 1}ã€‘\n{message.content}\n\n"
    
    summary_text += f"ç·ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸æ•°: {len(messages)} ä»¶\n"
    summary_text += f"ä¼šè©±ã‚¿ãƒ¼ãƒ³æ•°: {len(messages)//2} ã‚¿ãƒ¼ãƒ³\n"
    
    return summary_text

class ChatInput:
    """ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ç®¡ç†ã‚¯ãƒ©ã‚¹ï¼ˆChatç‰ˆï¼‰"""
    def __init__(self):
        self.multi_mode = False
    
    def get_user_input(self):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’å–å¾—ï¼ˆ1è¡Œå…¥åŠ›ãƒ»è¤‡æ•°è¡Œãƒ¢ãƒ¼ãƒ‰åˆ‡ã‚Šæ›¿ãˆå¯¾å¿œï¼‰"""
        while True:
            if not self.multi_mode:
                user_input = input("\nã‚ãªãŸ: ").strip()
                
                # çµ‚äº†ã‚³ãƒãƒ³ãƒ‰
                if user_input.lower() in ["ã•ã‚ˆã†ãªã‚‰", "bye", "exit", "quit"]:
                    return user_input
                
                # è¤‡æ•°è¡Œãƒ¢ãƒ¼ãƒ‰ã‚³ãƒãƒ³ãƒ‰ï¼ˆè¡Œã®å…ˆé ­ã§å®Œå…¨ä¸€è‡´ã®å ´åˆã®ã¿ï¼‰
                if user_input.lower() in ["multi", "è¤‡æ•°è¡Œ"]:
                    print("=== Chat è¤‡æ•°è¡Œå…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ ===")
                    print("è¤‡æ•°è¡Œã§ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    print("çµ‚äº†ã™ã‚‹ã«ã¯ Ctrl+Z ã‚’æŠ¼ã—ã¦ãã ã•ã„ã€‚")
                    print("1è¡Œãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã‚‹ã«ã¯ 'single' ã¨å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    print("ç·¨é›†æ©Ÿèƒ½:")
                    print("  'show' - ç¾åœ¨ã®å…¥åŠ›å†…å®¹ã‚’è¡¨ç¤º")
                    print("  'clear' - å…¥åŠ›å†…å®¹ã‚’ã‚¯ãƒªã‚¢")
                    print("  'ã‚‚ã¨ã„' / 'ã¡ã‚ƒã„ã¡ã‚ƒã„' - ç›´å‰ã®è¡Œã‚’å‰Šé™¤")
                    print("ç‰¹åˆ¥æ©Ÿèƒ½:")
                    print("  'ã¾ã¨ã‚ã¦ãã ã•ã„' - ä¼šè©±å±¥æ­´ã‚’AIãŒã¾ã¨ã‚ã¦ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜")
                    print("-" * 40)
                    self.multi_mode = True
                    continue
                
                # é€šå¸¸ã®1è¡Œå…¥åŠ›
                if user_input:
                    return user_input
                
                # ç©ºå…¥åŠ›ã®å ´åˆã¯å†å…¥åŠ›ã‚’ä¿ƒã™
                print("è³ªå•ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            
            else:  # è¤‡æ•°è¡Œãƒ¢ãƒ¼ãƒ‰
                lines = []
                try:
                    while True:
                        try:
                            line = input()
                            
                            # singleã‚³ãƒãƒ³ãƒ‰ã§1è¡Œãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã‚‹
                            if line.strip().lower() == "single":
                                print("1è¡Œå…¥åŠ›ãƒ¢ãƒ¼ãƒ‰ã«æˆ»ã‚Šã¾ã™ã€‚")
                                self.multi_mode = False
                                break
                            
                            # ç·¨é›†ã‚³ãƒãƒ³ãƒ‰ç¾¤
                            elif line.strip().lower() == "show":
                                if lines:
                                    print(f"\nç¾åœ¨ã®å…¥åŠ›å†…å®¹ ({len(lines)}è¡Œ):")
                                    print("-" * 20)
                                    for i, l in enumerate(lines, 1):
                                        print(f"{i:2}: {l}")
                                    print("-" * 20)
                                else:
                                    print("å…¥åŠ›å†…å®¹ã¯ç©ºã§ã™ã€‚")
                                continue
                            
                            elif line.strip().lower() == "clear":
                                lines.clear()
                                print("å…¥åŠ›å†…å®¹ã‚’ã‚¯ãƒªã‚¢ã—ã¾ã—ãŸã€‚")
                                continue
                            
                            elif line.strip().lower() in ["ã‚‚ã¨ã„", "ã¡ã‚ƒã„ã¡ã‚ƒã„"]:
                                if lines:
                                    removed_line = lines.pop()
                                    # å‰Šé™¤é€šçŸ¥ã¨åˆ‡ã‚Šå–ã‚Šç·šã‚’è¡¨ç¤º
                                    print(f"å‰Šé™¤: '{removed_line}'")
                                    print("-- >8 --")
                                    # ç¾åœ¨ã®å†…å®¹ã‚’å†è¡¨ç¤º
                                    for existing_line in lines:
                                        print(existing_line)
                                else:
                                    print("å‰Šé™¤ã™ã‚‹è¡ŒãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                                continue
                            
                            lines.append(line)
                            
                        except EOFError:
                            # Ctrl+Z ãŒæŠ¼ã•ã‚ŒãŸ
                            break
                except KeyboardInterrupt:
                    print("\nå…¥åŠ›ã‚’ã‚­ãƒ£ãƒ³ã‚»ãƒ«ã—ã¾ã—ãŸã€‚")
                    continue
                
                if lines:
                    result = '\n'.join(lines)
                    # è¤‡æ•°è¡Œå…¥åŠ›ãŒå®Œäº†ã€çµæœã‚’è¿”ã—è¤‡æ•°è¡Œãƒ¢ãƒ¼ãƒ‰ã¯ç¶™ç¶š
                    return result
                elif self.multi_mode and not lines:
                    print("å…¥åŠ›å†…å®¹ãŒç©ºã§ã™ã€‚å†åº¦å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                    # è¤‡æ•°è¡Œãƒ¢ãƒ¼ãƒ‰ã‚’ç¶™ç¶š


def get_user_input():
    """å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã®é–¢æ•°ï¼ˆéæ¨å¥¨ï¼‰"""
    global chat_input
    if 'chat_input' not in globals():
        chat_input = ChatInput()
    return chat_input.get_user_input()

def main():
    # ãƒãƒ¼ã‚¸ãƒ§ãƒ³æƒ…å ±ã‚’è¡¨ç¤º
    print_version_info()
    
    conversation_history = None
    conversation_log_filename = None
    ai_assistant = None
    model_name = None
    csv_writer = None
    log_file_handle = None
    id_num = 1 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®é–‹å§‹ã‚¿ãƒ¼ãƒ³ID
    
    # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ç®¡ç†ã‚¯ãƒ©ã‚¹ã‚’åˆæœŸåŒ–
    chat_input = ChatInput()

    try:
        # AI Assistantsè¨­å®šã‚’èª­ã¿è¾¼ã¿
        ai_assistants = load_ai_assistants_config()
        if not ai_assistants:
            print("[ERROR] AI Assistantsè¨­å®šã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
            return

        # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã§ -a ã‚„ -m ãŒæŒ‡å®šã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
        assistant_specified = '-a' in sys.argv or '--assistant' in sys.argv
        model_specified = '-m' in sys.argv or '--model' in sys.argv

        args = parse_arguments(ai_assistants) # å¼•æ•°ã‚’è§£æ
        ai_assistant = args.assistant
        model_name = args.model
        load_log_path = args.load_log
        
        # --latest ã‚ªãƒ—ã‚·ãƒ§ãƒ³ã®å‡¦ç†
        if args.latest:
            latest_log = find_latest_log()
            if latest_log:
                load_log_path = latest_log
                print(f"[INFO] --latest ã«ã‚ˆã‚Šæœ€æ–°ãƒ­ã‚° {latest_log} ã‚’èª­ã¿è¾¼ã¿ã¾ã™ã€‚")
            else:
                print(f"[WARNING] --latest ãŒæŒ‡å®šã•ã‚Œã¾ã—ãŸãŒã€{LOGS_DIR}/ ãƒ•ã‚©ãƒ«ãƒ€ã«ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        
        # ãƒ­ã‚°ãƒ‘ã‚¹ã®è§£æ±º
        if load_log_path:
            load_log_path = resolve_log_path(load_log_path)

        print("--- åˆæœŸè¨­å®š ---")
        print("AI Assistant:", ai_assistant)
        print("Model name:", model_name)
        print("----------------")

        initial_messages = []
        last_ai_assistant_from_log = None
        last_model_name_from_log = None

        if load_log_path:
            initial_messages, last_turn_id, last_ai_assistant_from_log, last_model_name_from_log = load_history_from_csv(load_log_path)

            if last_turn_id > 0:
                id_num = last_turn_id + 1
                print(f"ä¼šè©±ã‚’ã‚¿ãƒ¼ãƒ³ID {id_num} ã‹ã‚‰å†é–‹ã—ã¾ã™ã€‚")

                # ãƒ­ã‚°ã‹ã‚‰ãƒ¢ãƒ‡ãƒ«è¨­å®šã‚’ç¶™ç¶šã™ã‚‹ã‹ã®åˆ¤å®š
                if args.ignore_log_model:
                    # --ignore-log-model ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€ãƒ­ã‚°è¨­å®šã‚’ç„¡è¦–
                    print(f"[INFO] --ignore-log-model ã«ã‚ˆã‚Šã€ãƒ­ã‚°ã®è¨­å®šã‚’ç„¡è¦–ã—ã¦ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                elif args.confirm_model:
                    # --confirm-model ãŒæŒ‡å®šã•ã‚ŒãŸå ´åˆã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ã«ç¢ºèª
                    print(f"\nãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®è¨­å®š: Assistant={last_ai_assistant_from_log}, Model={last_model_name_from_log}")
                    print(f"ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³è¨­å®š: Assistant={ai_assistant}, Model={model_name}")
                    while True:
                        choice = input("ã©ã¡ã‚‰ã®è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã‹ï¼Ÿ [L]ogè¨­å®š / [C]ommandè¨­å®š / [Q]uit: ").lower().strip()
                        if choice in ['l', 'log']:
                            if last_ai_assistant_from_log in ai_assistants:
                                ai_assistant = last_ai_assistant_from_log
                                model_name = last_model_name_from_log
                                print(f"ãƒ­ã‚°è¨­å®šã‚’æ¡ç”¨ã—ã¾ã™: {ai_assistant}/{model_name}")
                            else:
                                print(f"[WARNING] ãƒ­ã‚°ã®AI Assistant '{last_ai_assistant_from_log}' ãŒç„¡åŠ¹ã§ã™ã€‚ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³è¨­å®šã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                            break
                        elif choice in ['c', 'command']:
                            print(f"ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³è¨­å®šã‚’æ¡ç”¨ã—ã¾ã™: {ai_assistant}/{model_name}")
                            break
                        elif choice in ['q', 'quit']:
                            print("ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
                            return
                        else:
                            print("L, C, Q ã®ã„ãšã‚Œã‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                elif not assistant_specified and not model_specified and last_ai_assistant_from_log and last_model_name_from_log:
                    # å¾“æ¥ã®è‡ªå‹•ç¶™ç¶šãƒ­ã‚¸ãƒƒã‚¯ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå‹•ä½œï¼‰
                    if last_ai_assistant_from_log in ai_assistants:
                         print(f"[INFO] -a, -m æŒ‡å®šãªã—ã®ãŸã‚ã€ãƒ­ã‚°è¨­å®šï¼ˆAssistant: {last_ai_assistant_from_log}, Model: {last_model_name_from_log}ï¼‰ã‚’å¼•ãç¶™ãã¾ã™ã€‚")
                         ai_assistant = last_ai_assistant_from_log
                         model_name = last_model_name_from_log
                    else:
                         print(f"[WARNING] ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æœ€å¾Œã®AI Assistantå '{last_ai_assistant_from_log}' ã¯ç¾åœ¨æœ‰åŠ¹ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š ({args.assistant}/{args.model}) ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                else:
                    # -a ã¾ãŸã¯ -m ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã€ãã‚Œã‚’å„ªå…ˆ
                    print(f"[INFO] ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ãŒæŒ‡å®šã•ã‚Œã¦ã„ã‚‹ãŸã‚ã€æŒ‡å®šè¨­å®šï¼ˆ{ai_assistant}/{model_name}ï¼‰ã‚’ä½¿ç”¨ã—ã¾ã™ã€‚")
                
                # æœ€çµ‚è¨­å®šã‚’è¡¨ç¤º
                print("--- æœ€çµ‚è¨­å®š ---")
                print("AI Assistant:", ai_assistant)
                print("Model name:", model_name)
                print("----------------")

            else:
                print("ãƒ­ã‚°ã‹ã‚‰ã®å±¥æ­´èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ãŸã‹ã€å±¥æ­´ãŒç©ºã§ã—ãŸã€‚æ–°è¦ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
                load_log_path = None # ãƒ­ã‚°èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã¯æ–°è¦æ‰±ã„ã«ã™ã‚‹
        else:
             print("æ–°è¦ä¼šè©±ã‚’é–‹å§‹ã—ã¾ã™ã€‚")

        # --- CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ ---
        log_mode = 'w' # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æ–°è¦ä½œæˆãƒ¢ãƒ¼ãƒ‰
        write_header = True # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼æ›¸ãè¾¼ã¿ã‚ã‚Š

        if load_log_path and initial_messages: # ãƒ­ã‚°ã‚’èª­ã¿è¾¼ã‚“ã§ç¶™ç¶šã™ã‚‹å ´åˆ
            conversation_log_filename = load_log_path # æ—¢å­˜ã®ãƒ•ã‚¡ã‚¤ãƒ«åã‚’ãã®ã¾ã¾ä½¿ã†
            log_mode = 'a' # è¿½è¨˜ãƒ¢ãƒ¼ãƒ‰ã«å¤‰æ›´
            write_header = False # ãƒ˜ãƒƒãƒ€ãƒ¼ã¯æ›¸ãè¾¼ã¾ãªã„
            print(f"æ—¢å­˜ã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ« {conversation_log_filename} ã«è¿½è¨˜ã—ã¾ã™ã€‚")
        else: # æ–°è¦ä¼šè©±ã®å ´åˆ
            timestamp_start = datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # logsãƒ•ã‚©ãƒ«ãƒ€ã‚’ä½œæˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆï¼‰
            os.makedirs(LOGS_DIR, exist_ok=True)
            
            conversation_log_filename = os.path.join(LOGS_DIR, f"{timestamp_start}.csv")
            print(f"ä¼šè©±ãƒ­ã‚°ã‚’ {conversation_log_filename} ã«ä¿å­˜ã—ã¾ã™ã€‚")
            # log_mode ã¨ write_header ã¯ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®ã¾ã¾

        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ãã€CSVãƒ©ã‚¤ã‚¿ãƒ¼ã‚’æº–å‚™ (ãƒ¢ãƒ¼ãƒ‰ã¨ãƒ˜ãƒƒãƒ€ãƒ¼æ›¸ãè¾¼ã¿ã‚’å‹•çš„ã«)
            log_file_handle = open(conversation_log_filename, log_mode, newline='', encoding='utf-8')
            csv_writer = csv.writer(log_file_handle)
            if write_header:
                header = ['Timestamp', 'TurnID', 'Speaker', 'Content', 'ExecutionTimeSeconds', 'AI_Assistant', 'ModelName', 'ExecStatus']
                csv_writer.writerow(header)

        except Exception as e:
            print(f"[ERROR] ä¼šè©±ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«(CSV)ã®æº–å‚™ï¼ˆ{'è¿½è¨˜' if log_mode == 'a' else 'æ–°è¦ä½œæˆ'}ï¼‰ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
            conversation_log_filename = None
            if log_file_handle:
                log_file_handle.close()
        # ------------------------

        if conversation_log_filename is None:
             print("[ERROR] ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®æº–å‚™ã«å¤±æ•—ã—ãŸãŸã‚ã€å‡¦ç†ã‚’ç¶šè¡Œã§ãã¾ã›ã‚“ã€‚")
             return # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ãŒãªã„ã¨å‹•ä½œã§ããªã„ã®ã§çµ‚äº†

        llm = load_assistant(ai_assistants, ai_assistant, model_name)
        prompt = create_prompt(ai_assistant)

        # ä¼šè©±å±¥æ­´ã‚’åˆæœŸåŒ–
        conversation_history = ConversationHistory(max_length=MAX_HISTORY_LENGTH)
        # èª­ã¿è¾¼ã‚“ã å±¥æ­´ã‚’è¨­å®š
        if initial_messages:
             try:
                 # å±¥æ­´ã¯å¸¸ã«æœ€æ–°ã‹ã‚‰ k*2 ä»¶ã«çµã£ã¦å¾©å…ƒ
                 relevant_history = initial_messages[-(MAX_HISTORY_LENGTH * 2):]
                 conversation_history.extend_messages(relevant_history)
                 print(f"å±¥æ­´ã«æœ€å¾Œã®{len(relevant_history)}ä»¶ã®ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å¾©å…ƒã—ã¾ã—ãŸã€‚")
             except Exception as e:
                  print(f"[ERROR] å±¥æ­´å¾©å…ƒä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

        def get_history_messages():
            """å±¥æ­´ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å–å¾—ã™ã‚‹é–¢æ•°"""
            return conversation_history.get_messages()

        conversation = RunnableSequence(
            RunnablePassthrough.assign(
                history=RunnableLambda(lambda x: get_history_messages())
            ),
            prompt,
            llm
        )

        while True:
            # ãƒãƒ£ãƒƒãƒˆå…¥åŠ›ã‚¯ãƒ©ã‚¹ã‚’ä½¿ç”¨
            user_question = chat_input.get_user_input()

            if user_question.strip().lower() in ["", "ã•ã‚ˆã†ãªã‚‰", "bye", "exit", "quit"]:
                break

            if user_question:
                # ã¾ã¨ã‚è¦æ±‚ã®æ¤œå‡ºã¨å‡¦ç†
                if is_summary_request(user_question):
                    print("ğŸ“‹ ã¾ã¨ã‚è¦æ±‚ã‚’æ¤œå‡ºã—ã¾ã—ãŸã€‚ä¼šè©±å±¥æ­´ã‚’ã¾ã¨ã‚ã¦ã„ã¾ã™...")
                    
                    # ä¼šè©±å±¥æ­´ã‹ã‚‰ã¾ã¨ã‚ç”¨ãƒ†ã‚­ã‚¹ãƒˆã‚’ä½œæˆ
                    history_summary = create_conversation_summary(conversation_history)
                    
                    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’CSVãƒ­ã‚°ã«è¨˜éŒ²
                    if csv_writer:
                        try:
                            timestamp_log = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            row_data = [timestamp_log, id_num, 'User', user_question, '', ai_assistant, model_name, '']
                            csv_writer.writerow(row_data)
                            log_file_handle.flush()
                        except Exception as e:
                            print(f"[ERROR] CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    
                    # AIã«ã‚ˆã‚‹ã¾ã¨ã‚ç”Ÿæˆ
                    summary_prompt = f"""ä»¥ä¸‹ã®ä¼šè©±å±¥æ­´ã‚’ã¾ã¨ã‚ã¦ãã ã•ã„ã€‚ä¸»è¦ãªãƒã‚¤ãƒ³ãƒˆã€çµè«–ã€é‡è¦ãªæƒ…å ±ã‚’æ•´ç†ã—ã¦åˆ†ã‹ã‚Šã‚„ã™ãã¾ã¨ã‚ã¦ãã ã•ã„ã€‚

{history_summary}

ã¾ã¨ã‚ã‚‹éš›ã¯ä»¥ä¸‹ã®ç‚¹ã‚’å¿ƒãŒã‘ã¦ãã ã•ã„ï¼š
- é‡è¦ãªã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚„æ¦‚å¿µã¯ [[ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰]] ã®å½¢å¼ã§å›²ã‚“ã§ãƒªãƒ³ã‚¯åŒ–ã—ã¦ãã ã•ã„
- é–¢é€£ã™ã‚‹ãƒˆãƒ”ãƒƒã‚¯ã‚„æŠ€è¡“ç”¨èªã‚‚ [[]] ã§å›²ã‚“ã§ãã ã•ã„
- #ã‚¿ã‚° ã‚‚é©åˆ‡ã«ä»˜ä¸ã—ã¦ãã ã•ã„
- ä»–ã®ãƒãƒ¼ãƒˆã¨ã®ã¤ãªãŒã‚Šã‚’æ„è­˜ã—ãŸæ›¸ãæ–¹ã‚’ã—ã¦ãã ã•ã„

ä¸Šè¨˜ã®ä¼šè©±ã‚’ç°¡æ½”ã«ã¾ã¨ã‚ã¦ãã ã•ã„ï¼š"""
                    
                    start_time = time.time()
                    ai_response_content = None
                    exec_status = 'Failure'
                    response_message = None
                    
                    # AIã«ã‚ˆã‚‹ã¾ã¨ã‚ç”Ÿæˆï¼ˆãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãï¼‰
                    max_retries = 3
                    retry_delay = 60
                    
                    for attempt in range(max_retries):
                        try:
                            response_message = conversation.invoke({"input": summary_prompt})
                            if isinstance(response_message, AIMessage):
                                ai_response_content = response_message.content
                                exec_status = 'Success'
                                break
                            else:
                                ai_response_content = 'ã¾ã¨ã‚ã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚'
                                break
                        except Exception as e:
                            error_str = str(e)
                            print(f"ã¾ã¨ã‚ç”Ÿæˆã‚¨ãƒ©ãƒ¼ (è©¦è¡Œ {attempt + 1}/{max_retries}): {e}")
                            
                            if "429" in error_str or "rate limit" in error_str.lower():
                                if attempt < max_retries - 1:
                                    wait_time = retry_delay * (2 ** attempt)
                                    print(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¾ã™...")
                                    time.sleep(wait_time)
                                    continue
                            
                            ai_response_content = f"ã¾ã¨ã‚ç”Ÿæˆã‚¨ãƒ©ãƒ¼: {e}"
                            if attempt == max_retries - 1:
                                print(f"æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")
                            break
                    
                    end_time = time.time()
                    run_time = round(end_time - start_time, 3)
                    
                    if ai_response_content:
                        print(f"\nğŸ“‹ ä¼šè©±ã¾ã¨ã‚ï¼ˆ{ai_assistant}:{model_name}ï¼‰:\n{ai_response_content}")
                        
                        # ã¾ã¨ã‚ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                        summary_filename = save_summary_to_file(ai_response_content, ai_assistant, model_name)
                        
                        # ä¼šè©±å±¥æ­´ã«ã¾ã¨ã‚ã®ã‚„ã‚Šå–ã‚Šã‚’è¿½åŠ 
                        conversation_history.add_message(HumanMessage(content=user_question))
                        if response_message:
                            conversation_history.add_message(response_message)
                    
                    print(f"\n--------------------\nå®Ÿè¡Œæ™‚é–“: {run_time:.3f}ç§’\n--------------------")
                    
                    # ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”ã‚’CSVãƒ­ã‚°ã«è¨˜éŒ²
                    if csv_writer:
                        try:
                            timestamp_log = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                            row_data = [timestamp_log, id_num, 'Assistant', ai_response_content, run_time, ai_assistant, model_name, exec_status]
                            csv_writer.writerow(row_data)
                            log_file_handle.flush()
                        except Exception as e:
                            print(f"[ERROR] CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                    
                    id_num += 1
                    continue  # ã¾ã¨ã‚å‡¦ç†å®Œäº†ã€é€šå¸¸ã®å‡¦ç†ã‚’ã‚¹ã‚­ãƒƒãƒ—
                
                # --- é€šå¸¸ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’CSVãƒ­ã‚°ã«è¨˜éŒ² ---
                if csv_writer:
                    try:
                        timestamp_log = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        row_data = [timestamp_log, id_num, 'User', user_question, '', ai_assistant, model_name, '']
                        csv_writer.writerow(row_data)
                        log_file_handle.flush() # ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã—ã¦å³æ™‚æ›¸ãè¾¼ã¿
                    except Exception as e:
                        print(f"[ERROR] CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                # ----------------------------------

                start_time = time.time()
                ai_response_content = None
                exec_status = 'Failure'
                response_message = None
                
                # ãƒªãƒˆãƒ©ã‚¤æ©Ÿèƒ½ä»˜ãã§APIå‘¼ã³å‡ºã—
                max_retries = 3
                retry_delay = 60  # åˆæœŸå¾…æ©Ÿæ™‚é–“ï¼ˆç§’ï¼‰
                
                for attempt in range(max_retries):
                    try:
                        response_message = conversation.invoke({"input": user_question})
                        if isinstance(response_message, AIMessage):
                            ai_response_content = response_message.content
                            # ä¼šè©±å±¥æ­´ã«è¿½åŠ 
                            conversation_history.add_message(HumanMessage(content=user_question))
                            conversation_history.add_message(response_message)
                            exec_status = 'Success'
                            break  # æˆåŠŸã—ãŸã‚‰ãƒ«ãƒ¼ãƒ—ã‚’æŠœã‘ã‚‹
                        else:
                            ai_response_content = 'No valid output found from AI.'
                            break
                    except Exception as e:
                        error_str = str(e)
                        print(f"ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ (è©¦è¡Œ {attempt + 1}/{max_retries}): {e}")
                        
                        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ã®å ´åˆã®ç‰¹åˆ¥å‡¦ç†
                        if "429" in error_str or "rate limit" in error_str.lower():
                            if attempt < max_retries - 1:  # æœ€å¾Œã®è©¦è¡Œã§ãªã„å ´åˆ
                                wait_time = retry_delay * (2 ** attempt)  # æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•
                                print(f"ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«é”ã—ã¾ã—ãŸã€‚{wait_time}ç§’å¾…æ©Ÿã—ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¾ã™...")
                                time.sleep(wait_time)
                                continue
                        
                        # ãã®ä»–ã®ã‚¨ãƒ©ãƒ¼ã¾ãŸã¯æœ€å¾Œã®è©¦è¡Œã®å ´åˆ
                        ai_response_content = f"Error: {e}"
                        if attempt == max_retries - 1:
                            print(f"æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°ã«é”ã—ã¾ã—ãŸã€‚ã‚¨ãƒ©ãƒ¼: {e}")
                        break

                end_time = time.time()
                run_time = round(end_time - start_time, 3)

                if ai_response_content:
                    print(f"\nã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆï¼ˆ{ai_assistant}:{model_name}ï¼‰:\n{ai_response_content}")

                print(f"\n--------------------\nå®Ÿè¡Œæ™‚é–“: {run_time:.3f}ç§’\n--------------------")

                # --- ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”ã‚’CSVãƒ­ã‚°ã«è¨˜éŒ² ---
                if csv_writer:
                    try:
                        timestamp_log = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                        row_data = [timestamp_log, id_num, 'Assistant', ai_response_content, run_time, ai_assistant, model_name, exec_status]
                        csv_writer.writerow(row_data)
                        log_file_handle.flush() # ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã—ã¦å³æ™‚æ›¸ãè¾¼ã¿
                    except Exception as e:
                        print(f"[ERROR] CSVãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã¸ã®ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆå¿œç­”æ›¸ãè¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
                # ------------------------------------

                id_num += 1

    except Exception as e:
         # main é–¢æ•°ãƒ¬ãƒ™ãƒ«ã§ã®äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼
         print(f"[FATAL ERROR] ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã®å®Ÿè¡Œä¸­ã«äºˆæœŸã›ã¬ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
         import traceback
         traceback.print_exc() # ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚’å‡ºåŠ›

    finally:
        print("Chat ã‚’çµ‚äº†ã—ã¾ã™ã€‚")
        if log_file_handle:
            try:
                log_file_handle.close()
                if conversation_log_filename: # ãƒ•ã‚¡ã‚¤ãƒ«åãŒç¢ºå®šã—ã¦ã„ã‚Œã°è¡¨ç¤º
                     print(f"ä¼šè©±ãƒ­ã‚°ã‚’ {conversation_log_filename} ã«ä¿å­˜ã—ã¾ã—ãŸã€‚")
            except Exception as e:
                print(f"[ERROR] ä¼šè©±ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«(CSV)ã®ã‚¯ãƒ­ãƒ¼ã‚ºã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

if __name__ == "__main__":
    main()
