# Quiz Evaluation Organization - 自称クイズ王バトル

このorganizationは、AI・技術分野のクイズ評価とモデル性能比較を「自称クイズ王」ロールで行う専門組織です。

## コンセプト
各AIモデルが「自称クイズ王」として登場し、自信満々にクイズに挑戦！
技術的な正確性を保ちながら、キャラクター性を持たせた楽しいクイズバトルを実現します。

## 目的
- 複数のAIプロバイダー（OpenAI、Google、Anthropic、Meta/Groq、Mistral、Together、xAI/Grok）のモデル性能を比較
- 統一されたキャラクター設定での公平な評価
- 楽しく分かりやすいクイズバトル形式での性能測定

## 参加モデル

### 自称クイズ王たち
- **OpenAI自称クイズ王**: GPT-5 (ChatGPT) - 「当然ですが、AIクイズなら私の独壇場です！」
- **Google自称クイズ王**: Gemini-2.5-Pro - 「機械学習は私の得意分野、楽勝ですね！」  
- **Anthropic自称クイズ王**: Claude-Opus-4 - 「論理的思考なら負けません、簡単な問題ですね」
- **Groq自称クイズ王**: Llama-4-Maverick-17B - 「高速回答が得意です、瞬殺します！」
- **Groq軽量自称クイズ王**: Llama-4-Scout-17B - 「軽量でも実力は一流ですから！」
- **Mistral自称クイズ王**: Mistral-Large-Latest - 「ヨーロッパの技術力を見せつけます！」
- **Together自称クイズ王**: RedPajama-INCITE-7B - 「オープンソースの真の力をどうぞ！」
- **Grok自称クイズ王**: Grok-4-0709 - 「xAIの革新的技術で驚かせますよ！」

## ロール設定

### 自称クイズ王の特徴
- 技術系クイズに絶対的な自信を持っている
- AI・機械学習・プログラミング・統計学・法律などあらゆる技術分野に精通していると自負
- 「当然ですが」「簡単ですね」「クイズ王の私には余裕です」などの自信満々なコメント
- でも実際には、真面目に問題と向き合い正確な回答を心がける

## ワークフロー

### 1. quiz_battle（自称クイズ王バトル）
各AIプロバイダーの自称クイズ王による技術クイズ対決

### 2. model_comparison（AIモデル性能比較）
異なるAIモデルのクイズ性能を自称クイズ王として比較評価

## シナリオ

### ultimate_quiz_battle
各AIプロバイダーの最強クイズ王による究極バトル
- OpenAI 最強クイズ王
- Google 無敵クイズ王  
- Anthropic 絶対クイズ王
- Meta 伝説クイズ王
- Mistral 究極クイズ王
- Together 至高クイズ王
- Grok 革命クイズ王

## 使用方法

### 基本的な使用方法

```bash
# 自称クイズ王バトルで20問クイズを実行
python MultiRoleChat.py -org quiz_evaluation -w quiz_battle -n 20

# モデル比較での連続クイズ
python MultiRoleChat.py -org quiz_evaluation -w model_comparison -cq

# 究極クイズ王バトル
python MultiRoleChat.py -org quiz_evaluation -s ultimate_quiz_battle -n 10
```

### 対話モード（推奨）

```bash
# デモモードで対話的にクイズを実行
python MultiRoleChat.py --org quiz_evaluation --demo

# 実行後に以下のコマンドを入力
🎭 MultiRoleChat> quiz multiline continuous
```

## 期待される効果
- 統一されたキャラクター設定による公平な比較
- エンターテイメント性のあるクイズ評価
- 各モデルの個性が出やすい環境での性能測定
- 見やすく楽しい結果分析

## クイズによる性能評価

### 実施例コマンド

```bash
C:\work\llm-chat-system> python MultiRoleChat.py --org quiz_evaluation --demo
🎭 MultiRoleChat> quiz multiline continuous
```

### 📊 最新評価結果 (2025年08月16日実施)

**出題元**: [日本ディープラーニング協会 G検定問題](https://www.jdla.org/certificate/general/issues/)  
**総問題数**: 20問（AI・機械学習・統計学・法律等の技術分野）

#### 🎯 正解率ランキング
| 順位 | AI自称クイズ王 | 正解率 | 不正解問題 |
|------|--------------|--------|----------|
| 🥇 1位（同率） | OpenAI自称クイズ王 (GPT-5) | **100.0%** | なし |
| 🥇 1位（同率） | Google自称クイズ王 (Gemini-2.5-Pro) | **100.0%** | なし |
| 🥇 1位（同率） | Anthropic自称クイズ王 (Claude-Opus-4) | **100.0%** | なし |
| 🥇 1位（同率） | Groq自称クイズ王 (Llama-4-Maverick-17B) | **100.0%** | なし |
| 🥇 1位（同率） | Mistral自称クイズ王 (Mistral-Large-Latest) | **100.0%** | なし |
| 🥇 1位（同率） | Grok自称クイズ王 (Grok-4-0709) | **100.0%** | なし |
| 🥈 7位 | Groq軽量自称クイズ王 (Llama-4-Scout-17B) | **95.0%** | Q5のみ |

#### ⚡ 応答速度ランキング
| 順位 | AI自称クイズ王 | 平均応答時間 | 最速記録 | 応答成功率 |
|------|--------------|-------------|----------|-----------|
| 🏆 1位 | **Groq軽量自称クイズ王** | **0.78秒** | 0.41秒 | 100% |
| 🥈 2位 | Groq自称クイズ王 | 1.17秒 | 0.52秒 | 100% |
| 🥉 3位 | Mistral自称クイズ王 | 1.78秒 | 0.53秒 | 100% |
| 4位 | Anthropic自称クイズ王 | 6.74秒 | 4.04秒 | 100% |
| 5位 | Grok自称クイズ王 | 8.56秒 | 4.37秒 | 100% |
| 6位 | Google自称クイズ王 | 9.78秒 | 4.76秒 | 100% |
| 7位 | OpenAI自称クイズ王 | 10.30秒 | 2.93秒 | 100% |

#### 🏁 早押しクイズ王決定戦
**Groq軽量自称クイズ王**が圧倒的な強さで早押し王に君臨！
- **最速回答数**: 20問中18問で最速回答
- **最速記録**: 0.41秒（瞬間回答）
- **総合評価**: 速度と精度（95%）の絶妙なバランス

#### 📈 主要な発見
- **精度面**: 7つ中6つのモデルが完璧な100%正解率を達成
- **速度面**: Groqプロバイダーが圧倒的な高速性能を発揮
- **安定性**: Together以外の全プロバイダーが安定動作
- **実用性**: リアルタイム応答が必要なアプリケーションにはGroq軽量が最適

#### ⚠️ 注意事項
- Together自称クイズ王 (meta-llama/Llama-Guard-4-12B) は全問でAPIエラーが発生
- Groq軽量自称クイズ王はQ5（レコメンデーション手法）で「協調フィルタリング」と回答（正解は「コンテンツベースフィルタリング」）

### 🎯 用途別おすすめモデル
- **高精度重視**: OpenAI、Google、Anthropic、Groq、Mistral、Grok（全て100%）
- **高速回答重視**: Groq軽量（0.78秒）、Groq（1.17秒）
- **バランス重視**: Groq軽量（95%正解率 + 0.78秒の高速回答）
- **早押しクイズ**: Groq軽量（20問中18問で最速）

各AIモデルがどんな「自称クイズ王」ぶりを発揮するか、お楽しみに！
